### TÃ³m táº¯t  
Chi tiáº¿t vá» cÃ¡c giai Ä‘oáº¡n xÃ¢y dá»±ng mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (Large Language Models - LLMs), táº­p trung vÃ o hai giai Ä‘oáº¡n chÃ­nh: tiá»n huáº¥n luyá»‡n (pre-training) vÃ  tinh chá»‰nh (fine-tuning). Tiá»n huáº¥n luyá»‡n lÃ  quÃ¡ trÃ¬nh Ä‘Ã o táº¡o mÃ´ hÃ¬nh trÃªn má»™t táº­p dá»¯ liá»‡u vÄƒn báº£n khá»•ng lá»“ vÃ  Ä‘a dáº¡ng tá»« Internet, sÃ¡ch, Wikipedia, vÃ  cÃ¡c nguá»“n khÃ¡c. Má»¥c tiÃªu cá»§a giai Ä‘oáº¡n nÃ y lÃ  giÃºp mÃ´ hÃ¬nh há»c cÃ¡ch dá»± Ä‘oÃ¡n tá»« tiáº¿p theo trong cÃ¢u, tá»« Ä‘Ã³ phÃ¡t triá»ƒn kháº£ nÄƒng thá»±c hiá»‡n nhiá»u tÃ¡c vá»¥ ngÃ´n ngá»¯ khÃ¡c nhau nhÆ° tráº£ lá»i cÃ¢u há»i, dá»‹ch thuáº­t, phÃ¢n tÃ­ch cáº£m xÃºc mÃ  khÃ´ng cáº§n huáº¥n luyá»‡n riÃªng cho tá»«ng tÃ¡c vá»¥.  

Tinh chá»‰nh lÃ  bÆ°á»›c tiáº¿p theo sau tiá»n huáº¥n luyá»‡n, khi mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n thÃªm trÃªn má»™t táº­p dá»¯ liá»‡u cÃ³ gáº¯n nhÃ£n Ä‘áº·c thÃ¹ cá»§a má»™t lÄ©nh vá»±c hoáº·c á»©ng dá»¥ng cá»¥ thá»ƒ, nháº±m cáº£i thiá»‡n hiá»‡u suáº¥t vÃ  Ä‘á»™ chÃ­nh xÃ¡c cho cÃ¡c nhiá»‡m vá»¥ chuyÃªn biá»‡t nhÆ° chatbot dá»‹ch vá»¥ khÃ¡ch hÃ ng, cÃ´ng cá»¥ há»— trá»£ phÃ¡p lÃ½ hay phÃ¢n loáº¡i email. Tinh chá»‰nh giÃºp mÃ´ hÃ¬nh trá»Ÿ nÃªn phÃ¹ há»£p vÃ  chÃ­nh xÃ¡c hÆ¡n Ä‘á»‘i vá»›i dá»¯ liá»‡u vÃ  yÃªu cáº§u riÃªng cá»§a tá»«ng tá»• chá»©c hoáº·c ngÃ nh nghá».  

Viá»‡c xÃ¢y dá»±ng LLM yÃªu cáº§u nguá»“n dá»¯ liá»‡u lá»›n vÃ  chi phÃ­ tÃ­nh toÃ¡n ráº¥t cao, vÃ­ dá»¥ tiá»n huáº¥n luyá»‡n GPT-3 cÃ³ chi phÃ­ lÃªn Ä‘áº¿n 4,6 triá»‡u Ä‘Ã´ la. CÃ¡c mÃ´ hÃ¬nh ná»n táº£ng (foundational models) nhÆ° GPT-4 Ä‘Ã£ cÃ³ kháº£ nÄƒng máº¡nh máº½ nhÆ°ng Ä‘á»ƒ Ã¡p dá»¥ng vÃ o thá»±c táº¿ doanh nghiá»‡p thÃ¬ cáº§n pháº£i qua bÆ°á»›c tinh chá»‰nh. BÃ i giáº£ng cÅ©ng minh há»a cÃ¡c vÃ­ dá»¥ thá»±c táº¿ tá»« cÃ¡c cÃ´ng ty lá»›n nhÆ° SK Telecom, Harvey (cÃ´ng cá»¥ AI phÃ¡p lÃ½), vÃ  JP Morgan Chase Ä‘á»ƒ nháº¥n máº¡nh táº§m quan trá»ng cá»§a viá»‡c tinh chá»‰nh mÃ´ hÃ¬nh. Cuá»‘i cÃ¹ng, bÃ i giáº£ng giá»›i thiá»‡u sÆ¡ Ä‘á»“ tá»•ng quÃ¡t cá»§a quÃ¡ trÃ¬nh xÃ¢y dá»±ng LLM gá»“m dá»¯ liá»‡u, tiá»n huáº¥n luyá»‡n, vÃ  tinh chá»‰nh, Ä‘á»“ng thá»i phÃ¢n biá»‡t dá»¯ liá»‡u khÃ´ng gÃ¡n nhÃ£n (dÃ¹ng cho tiá»n huáº¥n luyá»‡n) vÃ  dá»¯ liá»‡u cÃ³ gÃ¡n nhÃ£n (dÃ¹ng cho tinh chá»‰nh).

![Parameters](/images/pre-fine-lec3.png)

### Nhá»¯ng Ä‘iá»ƒm ná»•i báº­t  
- ğŸ“š Tiá»n huáº¥n luyá»‡n lÃ  giai Ä‘oáº¡n Ä‘Ã o táº¡o mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u khá»•ng lá»“ khÃ´ng gÃ¡n nhÃ£n, giÃºp mÃ´ hÃ¬nh há»c cÃ¡ch dá»± Ä‘oÃ¡n tá»« tiáº¿p theo vÃ  lÃ m Ä‘Æ°á»£c nhiá»u tÃ¡c vá»¥ ngÃ´n ngá»¯ khÃ¡c nhau mÃ  khÃ´ng cáº§n huáº¥n luyá»‡n riÃªng.  
- ğŸ§© Tinh chá»‰nh lÃ  quÃ¡ trÃ¬nh Ä‘Ã o táº¡o láº¡i mÃ´ hÃ¬nh trÃªn dá»¯ liá»‡u cÃ³ gÃ¡n nhÃ£n Ä‘áº·c thÃ¹, nháº±m tá»‘i Æ°u mÃ´ hÃ¬nh cho cÃ¡c á»©ng dá»¥ng chuyÃªn biá»‡t trong tá»«ng lÄ©nh vá»±c.  
- ğŸ’¸ Chi phÃ­ tÃ­nh toÃ¡n vÃ  tÃ i nguyÃªn cho tiá»n huáº¥n luyá»‡n LLM ráº¥t lá»›n, vÃ­ dá»¥ GPT-3 tiÃªu tá»‘n 4,6 triá»‡u Ä‘Ã´ la.  
- ğŸ¢ CÃ¡c cÃ´ng ty lá»›n nhÆ° SK Telecom, Harvey, vÃ  JP Morgan sá»­ dá»¥ng tinh chá»‰nh Ä‘á»ƒ táº¡o ra cÃ¡c mÃ´ hÃ¬nh phÃ¹ há»£p vá»›i dá»¯ liá»‡u vÃ  nhu cáº§u riÃªng cá»§a há».  
- ğŸ”„ Tiá»n huáº¥n luyá»‡n sá»­ dá»¥ng dá»¯ liá»‡u khÃ´ng gÃ¡n nhÃ£n (unsupervised learning), trong khi tinh chá»‰nh sá»­ dá»¥ng dá»¯ liá»‡u cÃ³ gÃ¡n nhÃ£n (supervised learning).  
- ğŸ” MÃ´ hÃ¬nh ná»n táº£ng (foundational model) nhÆ° GPT-4 cÃ³ thá»ƒ xá»­ lÃ½ nhiá»u tÃ¡c vá»¥ nhÆ°ng váº«n cáº§n tinh chá»‰nh Ä‘á»ƒ Ä‘Ã¡p á»©ng yÃªu cáº§u cá»¥ thá»ƒ trong thá»±c táº¿.  
- ğŸ¯ QuÃ¡ trÃ¬nh xÃ¢y dá»±ng LLM gá»“m ba bÆ°á»›c chÃ­nh: thu tháº­p dá»¯ liá»‡u, tiá»n huáº¥n luyá»‡n, tinh chá»‰nh.

### Nhá»¯ng hiá»ƒu biáº¿t chÃ­nh  
- ğŸ“Š **Tiá»n huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u lá»›n giÃºp mÃ´ hÃ¬nh phÃ¡t triá»ƒn kháº£ nÄƒng tá»•ng quÃ¡t:** Khi LLM Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn hÃ ng trÄƒm tá»· tá»« tá»« nhiá»u nguá»“n khÃ¡c nhau, nÃ³ khÃ´ng chá»‰ há»c cÃ¡ch dá»± Ä‘oÃ¡n tá»« mÃ  cÃ²n phÃ¡t triá»ƒn kháº£ nÄƒng hiá»ƒu ngÃ´n ngá»¯ sÃ¢u sáº¯c, cho phÃ©p nÃ³ Ã¡p dá»¥ng kiáº¿n thá»©c Ä‘Ã³ vÃ o nhiá»u tÃ¡c vá»¥ khÃ¡c nhau nhÆ° tráº£ lá»i cÃ¢u há»i, dá»‹ch thuáº­t, hay phÃ¢n tÃ­ch cáº£m xÃºc mÃ  khÃ´ng cáº§n huáº¥n luyá»‡n riÃªng. ÄÃ¢y lÃ  bÆ°á»›c Ä‘á»™t phÃ¡ so vá»›i cÃ¡c mÃ´ hÃ¬nh NLP truyá»n thá»‘ng vá»‘n pháº£i huáº¥n luyá»‡n riÃªng biá»‡t cho tá»«ng tÃ¡c vá»¥.  
- ğŸ—ï¸ **Tinh chá»‰nh lÃ  bÆ°á»›c cáº§n thiáº¿t Ä‘á»ƒ cÃ¡ nhÃ¢n hÃ³a vÃ  tÄƒng Ä‘á»™ chÃ­nh xÃ¡c cho á»©ng dá»¥ng cá»¥ thá»ƒ:** MÃ´ hÃ¬nh ná»n táº£ng Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn dá»¯ liá»‡u rá»™ng vÃ  tá»•ng quÃ¡t, do Ä‘Ã³ khi Ã¡p dá»¥ng vÃ o cÃ¡c lÄ©nh vá»±c cá»¥ thá»ƒ nhÆ° phÃ¡p lÃ½, tÃ i chÃ­nh, hay dá»‹ch vá»¥ khÃ¡ch hÃ ng, cáº§n tinh chá»‰nh dá»±a trÃªn dá»¯ liá»‡u cÃ³ gÃ¡n nhÃ£n Ä‘áº·c thÃ¹ Ä‘á»ƒ mÃ´ hÃ¬nh hiá»ƒu sÃ¢u hÆ¡n vá» ngá»¯ cáº£nh vÃ  yÃªu cáº§u riÃªng, tá»« Ä‘Ã³ cáº£i thiá»‡n cháº¥t lÆ°á»£ng káº¿t quáº£ Ä‘áº§u ra.  
- ğŸ’° **Chi phÃ­ vÃ  tÃ i nguyÃªn lá»›n lÃ  rÃ o cáº£n quan trá»ng trong phÃ¡t triá»ƒn LLM:** Viá»‡c tiá»n huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh nhÆ° GPT-3 Ä‘Ã²i há»i hÃ ng triá»‡u Ä‘Ã´ la vÃ  sá»©c máº¡nh tÃ­nh toÃ¡n khá»•ng lá»“ (GPU, Ä‘iá»‡n nÄƒng), Ä‘iá»u nÃ y khiáº¿n viá»‡c phÃ¡t triá»ƒn má»™t LLM tá»« Ä‘áº§u ngoÃ i táº§m vá»›i cá»§a cÃ¡ nhÃ¢n hoáº·c nhÃ³m nhá», vÃ  chá»‰ cÃ¡c cÃ´ng ty lá»›n hoáº·c tá»• chá»©c cÃ³ nguá»“n lá»±c má»›i cÃ³ thá»ƒ thá»±c hiá»‡n.  
- ğŸ§  **MÃ´ hÃ¬nh ná»n táº£ng (foundational model) lÃ  cÆ¡ sá»Ÿ nhÆ°ng khÃ´ng pháº£i lÃ  sáº£n pháº©m cuá»‘i cÃ¹ng:** MÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n Ä‘Æ°á»£c gá»i lÃ  mÃ´ hÃ¬nh ná»n táº£ng vÃ¬ nÃ³ cÃ³ kháº£ nÄƒng xá»­ lÃ½ Ä‘a dáº¡ng tÃ¡c vá»¥, nhÆ°ng Ä‘á»ƒ Ä‘Æ°a vÃ o á»©ng dá»¥ng thá»±c táº¿ cáº§n pháº£i tinh chá»‰nh, bá»Ÿi vÃ¬ dá»¯ liá»‡u tiá»n huáº¥n luyá»‡n khÃ´ng bao gá»“m thÃ´ng tin Ä‘áº·c thÃ¹ cá»§a tá»«ng lÄ©nh vá»±c, nhÆ° dá»¯ liá»‡u phÃ¡p lÃ½ hay dá»¯ liá»‡u khÃ¡ch hÃ ng cá»§a má»™t cÃ´ng ty.  
- ğŸ”„ **PhÃ¢n biá»‡t rÃµ rÃ ng giá»¯a dá»¯ liá»‡u khÃ´ng gÃ¡n nhÃ£n vÃ  dá»¯ liá»‡u cÃ³ gÃ¡n nhÃ£n trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n:** Tiá»n huáº¥n luyá»‡n sá»­ dá»¥ng dá»¯ liá»‡u thÃ´ khÃ´ng gÃ¡n nhÃ£n vÃ  lÃ  quÃ¡ trÃ¬nh tá»± giÃ¡m sÃ¡t (auto-regression) trong viá»‡c dá»± Ä‘oÃ¡n tá»« tiáº¿p theo, cÃ²n tinh chá»‰nh Ä‘Ã²i há»i dá»¯ liá»‡u cÃ³ gÃ¡n nhÃ£n Ä‘á»ƒ mÃ´ hÃ¬nh há»c cÃ¡c nhiá»‡m vá»¥ Ä‘áº·c thÃ¹ nhÆ° phÃ¢n loáº¡i hoáº·c tráº£ lá»i cÃ¢u há»i vá»›i nhÃ£n chuáº©n xÃ¡c.  
- ğŸ“ˆ **CÃ¡c vÃ­ dá»¥ thá»±c táº¿ cho tháº¥y hiá»‡u quáº£ cá»§a tinh chá»‰nh:** SK Telecom tÄƒng 35% cháº¥t lÆ°á»£ng tÃ³m táº¯t há»™i thoáº¡i vÃ  33% Ä‘á»™ chÃ­nh xÃ¡c nháº­n dáº¡ng Ã½ Ä‘á»‹nh sau khi tinh chá»‰nh; Harvey trá»Ÿ thÃ nh cÃ´ng cá»¥ AI phÃ¡p lÃ½ tin cáº­y nhá» Ä‘Æ°á»£c tinh chá»‰nh trÃªn dá»¯ liá»‡u lá»‹ch sá»­ vá»¥ Ã¡n; JP Morgan phÃ¡t triá»ƒn bá»™ cÃ´ng cá»¥ LLM riÃªng cho ngÃ¢n hÃ ng dá»±a trÃªn dá»¯ liá»‡u ná»™i bá»™.  
- ğŸ“ **Hiá»ƒu biáº¿t vá» tiá»n huáº¥n luyá»‡n vÃ  tinh chá»‰nh giÃºp ngÆ°á»i dÃ¹ng sá»­ dá»¥ng hiá»‡u quáº£ mÃ´ hÃ¬nh LLM:** NgÆ°á»i dÃ¹ng phá»• thÃ´ng nhÆ° há»c sinh sinh viÃªn cÃ³ thá»ƒ sá»­ dá»¥ng mÃ´ hÃ¬nh tiá»n huáº¥n luyá»‡n nhÆ° GPT-4 Ä‘á»ƒ phá»¥c vá»¥ má»¥c Ä‘Ã­ch tÃ¬m kiáº¿m thÃ´ng tin hay há»c táº­p, trong khi cÃ¡c tá»• chá»©c doanh nghiá»‡p cáº§n Ä‘áº§u tÆ° tinh chá»‰nh Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c giáº£i phÃ¡p AI phÃ¹ há»£p vÃ  hiá»‡u quáº£ cho nghiá»‡p vá»¥ riÃªng.